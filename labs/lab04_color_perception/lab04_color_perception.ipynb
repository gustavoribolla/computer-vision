{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Color Perception and Color Spaces\n",
    "\n",
    "**Computer Vision Course**\n",
    "\n",
    "In this lab you will explore how different color spaces (RGB, HSV, HLS, Lab) affect image processing tasks. You'll see why simply working with RGB values is often not enough, and how choosing the right color space can make segmentation tasks much easier.\n",
    "\n",
    "**What you'll do:**\n",
    "- Segment the sky from an image using different color spaces\n",
    "- Understand HSV, HLS, and Lab color representations\n",
    "- Learn when each color space is useful\n",
    "- Debug common color conversion issues\n",
    "\n",
    "**Connection to previous labs:**\n",
    "- Lab 3 showed how image variations break models\n",
    "- Today you'll learn about one critical type of variation: **color**\n",
    "- Understanding color spaces is essential for robust computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computer Vision Course - Lab 4: Color Perception\n",
    "\n",
    "This cell sets up the environment.\n",
    "Works automatically for both local and Google Colab!\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Detect environment\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Computer Vision - Lab 4: Color Perception\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"\\nğŸ”µ Running on Google Colab\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if not os.path.exists('computer-vision'):\n",
    "        print(\"ğŸ“¥ Cloning repository...\")\n",
    "        !git clone https://github.com/mjck/computer-vision.git\n",
    "        print(\"âœ“ Repository cloned successfully\")\n",
    "    else:\n",
    "        print(\"âœ“ Repository already exists\")\n",
    "    \n",
    "    %cd computer-vision/labs/lab04_color_perception\n",
    "    print(f\"âœ“ Current directory: {os.getcwd()}\")\n",
    "    \n",
    "    sys.path.insert(0, '/content/computer-vision')\n",
    "    print(\"âœ“ Python path configured\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(\"ğŸŸ¢ Colab setup complete!\\n\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nğŸŸ¢ Running locally\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"âœ“ Current directory: {os.getcwd()}\")\n",
    "    \n",
    "    repo_root = os.path.abspath('../..')\n",
    "    if repo_root not in sys.path:\n",
    "        sys.path.insert(0, repo_root)\n",
    "    print(f\"âœ“ Repository root: {repo_root}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(\"ğŸŸ¢ Local setup complete!\\n\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"âœ… Environment ready!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import course utilities\n",
    "try:\n",
    "    from sdx import cv_imread, cv_imshow\n",
    "    print(\"âœ“ sdx module loaded\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Could not import sdx: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Check that sdx.py is in repository root\")\n",
    "    print(\"  2. Verify sys.path includes repository root\")\n",
    "    print(f\"  3. Current sys.path: {sys.path[:3]}\")\n",
    "    raise\n",
    "\n",
    "print(\"âœ“ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Displaying the Image\n",
    "\n",
    "We'll use a panoramic image of Insper. This time we'll work with the **full color** image, not grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv_imread('insper.png')\n",
    "\n",
    "cv_imshow(image)\n",
    "\n",
    "print(f\"Image loaded: {image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image is a three-dimensional array. The third dimension represents the **color channels**. OpenCV stores images in **BGR order** (Blue, Green, Red) instead of RGB, for [historical reasons](https://learnopencv.com/why-does-opencv-use-bgr-color-format/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, channels = image.shape\n",
    "\n",
    "print(f\"Dimensions: {height} Ã— {width} Ã— {channels}\")\n",
    "print(f\"Data type: {image.dtype}\")\n",
    "print(f\"Value range: [{image.min()}, {image.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 â€” Segmenting the Sky in BGR\n",
    "\n",
    "**Task:** Try to identify all pixels that belong to the sky.\n",
    "\n",
    "**Approach:** We'll look for pixels close to cyan (the sky color) using Euclidean distance in BGR color space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Target Color\n",
    "\n",
    "In BGR, cyan is `(255, 255, 0)` â€” high blue, high green, zero red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyan = np.array([255, 255, 0])  # BGR format\n",
    "\n",
    "print(f\"Target color (BGR): {cyan}\")\n",
    "print(f\"This is cyan: high blue + high green, no red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Function\n",
    "\n",
    "We'll measure how close each pixel is to cyan using Euclidean distance. We normalize by 255 so distances are in the range [0, âˆš3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_bgr(pixel, target):\n",
    "    \"\"\"\n",
    "    Compute normalized Euclidean distance between two BGR pixels.\n",
    "    \n",
    "    Args:\n",
    "        pixel: BGR pixel as (B, G, R) in [0, 255]\n",
    "        target: target BGR color as (B, G, R) in [0, 255]\n",
    "    \n",
    "    Returns:\n",
    "        Distance in [0, sqrt(3)] (normalized to [0, 1] range per channel)\n",
    "    \"\"\"\n",
    "    return np.linalg.norm((pixel - target) / 255.0)\n",
    "\n",
    "# Test it\n",
    "test_pixel = np.array([200, 220, 50])  # Sky-ish color\n",
    "print(f\"Distance from cyan to {test_pixel}: {distance_bgr(test_pixel, cyan):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1: Segment Using BGR Distance\n",
    "\n",
    "Let's try a threshold of 1.0 â€” any pixel within distance 1.0 of cyan is considered \"sky\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "\n",
    "# Create binary mask\n",
    "output = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        if distance_bgr(image[y, x], cyan) < threshold:\n",
    "            output[y, x] = 255\n",
    "\n",
    "cv_imshow(output)\n",
    "print(f\"Threshold: {threshold}\")\n",
    "print(f\"Sky pixels detected: {np.sum(output == 255):,} / {height * width:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¤” Observation\n",
    "\n",
    "That's not very good. We either:\n",
    "- Select too many pixels (false positives â€” grass, buildings)\n",
    "- Select too few pixels (false negatives â€” parts of sky missing)\n",
    "\n",
    "**Why?** BGR is not perceptually uniform. Similar-looking colors can be far apart in BGR space, and different-looking colors can be close together.\n",
    "\n",
    "Let's try other color spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2 â€” Using the HSV Color Space\n",
    "\n",
    "**HSV = Hue, Saturation, Value**\n",
    "\n",
    "- **Hue:** The color type (red, green, blue, etc.) â€” represented as an angle [0Â°, 360Â°]\n",
    "- **Saturation:** How pure/vivid the color is [0, 1] â€” low = grayish, high = vivid\n",
    "- **Value:** How bright the color is [0, 1] â€” low = dark, high = bright\n",
    "\n",
    "HSV separates *what color* (hue) from *how vivid* (saturation) and *how bright* (value). This often makes color-based segmentation easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "print(f\"HSV image shape: {hsv.shape}\")\n",
    "print(f\"HSV dtype: {hsv.dtype}\")\n",
    "print(f\"Sample pixel (BGR): {image[100, 200]}\")\n",
    "print(f\"Sample pixel (HSV): {hsv[100, 200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âš ï¸ **Important:** Don't use `cv_imshow()` on the HSV image directly! It will look weird because `cv_imshow()` expects BGR format. The HSV values are correct, just not meant for direct visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Activity 1 â€” Normalize HSV Values\n",
    "\n",
    "OpenCV stores HSV in a specific range. Read the [BGR to HSV documentation](https://docs.opencv.org/4.x/de/d25/imgproc_color_conversions.html#color_convert_rgb_hsv) and write a function that normalizes HSV pixels to standard ranges:\n",
    "\n",
    "- **H:** [0, 360] degrees\n",
    "- **S:** [0, 1]\n",
    "- **V:** [0, 1]\n",
    "\n",
    "**Hint:** OpenCV uses 8-bit storage, so values are scaled to fit in [0, 255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_hsv(pixel):\n",
    "    \"\"\"\n",
    "    Normalize HSV pixel from OpenCV's storage format to standard ranges.\n",
    "    \n",
    "    Args:\n",
    "        pixel: HSV pixel from OpenCV (H, S, V) in OpenCV's range\n",
    "    \n",
    "    Returns:\n",
    "        (h, s, v) tuple where:\n",
    "            h: float in [0, 360] (degrees)\n",
    "            s: float in [0, 1]\n",
    "            v: float in [0, 1]\n",
    "    \n",
    "    TODO: Read OpenCV documentation and implement this function.\n",
    "    Hint: OpenCV stores H in [0, 180], S in [0, 255], V in [0, 255]\n",
    "    \"\"\"\n",
    "    h, s, v = pixel\n",
    "    \n",
    "    # â”€â”€ Your code here â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    return h, s, v  # Replace with correct normalization\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Test your function\n",
    "test_hsv = hsv[100, 200]\n",
    "h, s, v = normalize_hsv(test_hsv)\n",
    "print(f\"\\nTest pixel (OpenCV format): {test_hsv}\")\n",
    "print(f\"Normalized: H={h:.1f}Â°, S={s:.3f}, V={v:.3f}\")\n",
    "print(\"\\nâœ“ If H is in [0, 360], S in [0, 1], V in [0, 1], you're correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Using HSV\n",
    "\n",
    "Now try to segment the sky using HSV thresholds. The sky is typically:\n",
    "- **Hue:** Around 180-220Â° (cyan/blue range)\n",
    "- **Saturation:** Medium to high (0.3-1.0) â€” it's a vivid color\n",
    "- **Value:** Medium to high (0.4-1.0) â€” it's bright\n",
    "\n",
    "Use Google's [color picker](https://www.google.com/search?q=color+picker) to experiment with HSV values and find good thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        h, s, v = normalize_hsv(hsv[y, x])\n",
    "        \n",
    "        # â”€â”€ Your thresholds here â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        # Replace this trivial condition with one based on h, s, v\n",
    "        # Example: if 180 < h < 220 and s > 0.3 and v > 0.4:\n",
    "        if True:  # TODO: Replace this!\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            output[y, x] = 255\n",
    "\n",
    "cv_imshow(output)\n",
    "print(f\"Sky pixels detected: {np.sum(output == 255):,} / {height * width:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Try to isolate just the sky. Experiment with different threshold ranges!\n",
    "\n",
    "**Tips:**\n",
    "- If you get too many false positives (grass, buildings), make your ranges tighter\n",
    "- If you get too many false negatives (missing sky), make your ranges wider\n",
    "- Hue is circular (0Â° and 360Â° are the same color â€” red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3 â€” Using the HLS Color Space\n",
    "\n",
    "**HLS = Hue, Lightness, Saturation**\n",
    "\n",
    "Similar to HSV, but uses **Lightness** instead of Value:\n",
    "- **Hue:** Same as HSV [0Â°, 360Â°]\n",
    "- **Lightness:** How light/dark [0, 1] â€” 0 = black, 0.5 = pure color, 1 = white\n",
    "- **Saturation:** How pure the color is [0, 1]\n",
    "\n",
    "HLS is sometimes better for tasks involving lighting variations.\n",
    "\n",
    "âš ï¸ **Note:** OpenCV calls it \"HLS\" not \"HSL\" (different ordering of letters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "print(f\"HLS image shape: {hls.shape}\")\n",
    "print(f\"Sample pixel (BGR): {image[100, 200]}\")\n",
    "print(f\"Sample pixel (HLS): {hls[100, 200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Activity 2 â€” Normalize HLS Values\n",
    "\n",
    "Read the [BGR to HLS documentation](https://docs.opencv.org/4.x/de/d25/imgproc_color_conversions.html#color_convert_rgb_hls) and write a normalization function for HLS:\n",
    "\n",
    "- **H:** [0, 360] degrees\n",
    "- **L:** [0, 1]\n",
    "- **S:** [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_hls(pixel):\n",
    "    \"\"\"\n",
    "    Normalize HLS pixel from OpenCV's storage format to standard ranges.\n",
    "    \n",
    "    Args:\n",
    "        pixel: HLS pixel from OpenCV (H, L, S) in OpenCV's range\n",
    "    \n",
    "    Returns:\n",
    "        (h, l, s) tuple where:\n",
    "            h: float in [0, 360] (degrees)\n",
    "            l: float in [0, 1]\n",
    "            s: float in [0, 1]\n",
    "    \n",
    "    TODO: Implement this based on OpenCV documentation.\n",
    "    \"\"\"\n",
    "    h, l, s = pixel\n",
    "    \n",
    "    # â”€â”€ Your code here â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    return h, l, s  # Replace with correct normalization\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Test\n",
    "test_hls = hls[100, 200]\n",
    "h, l, s = normalize_hls(test_hls)\n",
    "print(f\"\\nTest pixel (OpenCV format): {test_hls}\")\n",
    "print(f\"Normalized: H={h:.1f}Â°, L={l:.3f}, S={s:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Using HLS\n",
    "\n",
    "Now try segmenting the sky using HLS thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        h, l, s = normalize_hls(hls[y, x])\n",
    "        \n",
    "        # â”€â”€ Your thresholds here â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        if True:  # TODO: Replace with your condition\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            output[y, x] = 255\n",
    "\n",
    "cv_imshow(output)\n",
    "print(f\"Sky pixels detected: {np.sum(output == 255):,} / {height * width:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to think about:** Does HLS work better than HSV for this image? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4 â€” Using the Lab Color Space\n",
    "\n",
    "**Lab = Lightness, a, b**\n",
    "\n",
    "Lab is designed to be **perceptually uniform** â€” equal distances in Lab space correspond to equal perceived color differences.\n",
    "\n",
    "- **L:** Lightness [0, 100]\n",
    "- **a:** Green (-) to Red (+) axis\n",
    "- **b:** Blue (-) to Yellow (+) axis\n",
    "\n",
    "Lab is often used in color science and can be better for color matching tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "print(f\"Lab image shape: {lab.shape}\")\n",
    "print(f\"Sample pixel (BGR): {image[100, 200]}\")\n",
    "print(f\"Sample pixel (Lab): {lab[100, 200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Activity 3 â€” Normalize Lab Values\n",
    "\n",
    "Read the [BGR to Lab documentation](https://docs.opencv.org/4.x/de/d25/imgproc_color_conversions.html#color_convert_rgb_lab) and normalize Lab values:\n",
    "\n",
    "- **L:** [0, 100]\n",
    "- **a:** [-127, 127] (green to red)\n",
    "- **b:** [-127, 127] (blue to yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lab(pixel):\n",
    "    \"\"\"\n",
    "    Normalize Lab pixel from OpenCV's storage format to standard ranges.\n",
    "    \n",
    "    Args:\n",
    "        pixel: Lab pixel from OpenCV (L, a, b) in OpenCV's range\n",
    "    \n",
    "    Returns:\n",
    "        (L, a, b) tuple where:\n",
    "            L: float in [0, 100]\n",
    "            a: float in [-127, 127]\n",
    "            b: float in [-127, 127]\n",
    "    \n",
    "    TODO: Implement this. Careful with the a and b channels!\n",
    "    \"\"\"\n",
    "    L, a, b = pixel\n",
    "    \n",
    "    # â”€â”€ Your code here â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    return L, a, b  # Replace with correct normalization\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Test\n",
    "test_lab = lab[100, 200]\n",
    "L, a, b = normalize_lab(test_lab)\n",
    "print(f\"\\nTest pixel (OpenCV format): {test_lab}\")\n",
    "print(f\"Normalized: L={L:.1f}, a={a:.1f}, b={b:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Using Lab\n",
    "\n",
    "Try segmenting the sky in Lab space. \n",
    "\n",
    "**Hints for sky:**\n",
    "- L: Medium to high (bright)\n",
    "- a: Negative or near zero (no red, some green)\n",
    "- b: Negative (blue, not yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        L, a, b = normalize_lab(lab[y, x])\n",
    "        \n",
    "        # â”€â”€ Your thresholds here â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        if True:  # TODO: Replace with your condition\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            output[y, x] = 255\n",
    "\n",
    "cv_imshow(output)\n",
    "print(f\"Sky pixels detected: {np.sum(output == 255):,} / {height * width:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5 â€” Converting to Grayscale\n",
    "\n",
    "Finally, let's explore how to properly convert a color image to grayscale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Color Channels\n",
    "\n",
    "First, let's split the BGR image into its three channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, g, r = cv2.split(image)\n",
    "\n",
    "# Display each channel\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(b, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0].set_title('Blue channel')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(g, cmap='gray', vmin=0, vmax=255)\n",
    "axes[1].set_title('Green channel')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(r, cmap='gray', vmin=0, vmax=255)\n",
    "axes[2].set_title('Red channel')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Each channel shape: {b.shape}\")\n",
    "print(f\"Each channel dtype: {b.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Approach: Average the Channels\n",
    "\n",
    "The simplest approach is to average the three channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive grayscale conversion\n",
    "gray = (r + g + b) / 3\n",
    "\n",
    "cv_imshow(gray)\n",
    "\n",
    "print(f\"Gray image dtype: {gray.dtype}\")\n",
    "print(f\"Gray image range: [{gray.min():.1f}, {gray.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ› Challenge 1 â€” Fix the Bug\n",
    "\n",
    "Something is wrong! The image has weird artifacts. \n",
    "\n",
    "**Your task:**\n",
    "1. Figure out what went wrong\n",
    "2. Fix the code below\n",
    "3. Explain why the original code failed\n",
    "\n",
    "**Hint:** Check the data types involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Fix this code â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "gray = (r + g + b) / 3  # What's wrong here?\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "cv_imshow(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation (write your answer here):**\n",
    "\n",
    "*Why did the original code fail?*\n",
    "\n",
    "...\n",
    "\n",
    "*What did you change to fix it?*\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV's Grayscale Conversion\n",
    "\n",
    "Even with the bug fixed, your result might look slightly different from OpenCV's conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV's built-in grayscale conversion\n",
    "opencv_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv_imshow(opencv_gray)\n",
    "\n",
    "print(\"Compare the two grayscale images carefully.\")\n",
    "print(\"Can you see the difference? It's subtle but present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¬ Challenge 2 â€” OpenCV's Secret\n",
    "\n",
    "OpenCV doesn't simply average the three channels. It uses a **weighted** formula.\n",
    "\n",
    "**Your tasks:**\n",
    "1. Research what formula OpenCV uses for BGR â†’ grayscale\n",
    "2. Implement it below\n",
    "3. Explain **why** OpenCV uses this specific formula (hint: human vision)\n",
    "\n",
    "**Hint:** Search for \"ITU-R BT.601\" or look at OpenCV's color conversion documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Implement OpenCV's weighted grayscale conversion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "gray = (r + g + b) / 3  # Replace with weighted formula\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "cv_imshow(gray)\n",
    "\n",
    "# Compare to OpenCV's result\n",
    "difference = np.abs(gray.astype(float) - opencv_gray.astype(float))\n",
    "print(f\"\\nMax difference from OpenCV: {difference.max():.2f}\")\n",
    "print(f\"Mean difference: {difference.mean():.2f}\")\n",
    "print(\"\\nIf max difference < 1.0, your formula is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation (write your answer here):**\n",
    "\n",
    "*What formula does OpenCV use?*\n",
    "\n",
    "...\n",
    "\n",
    "*Why this formula? (Hint: Which color are human eyes most sensitive to?)*\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary and Reflection\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "Today you explored multiple color spaces:\n",
    "\n",
    "| Color Space | When to Use |\n",
    "|-------------|-------------|\n",
    "| **BGR/RGB** | Natural representation, but not perceptually uniform |\n",
    "| **HSV** | When you want to separate color (hue) from brightness; good for color-based segmentation |\n",
    "| **HLS** | Similar to HSV, but with different brightness representation |\n",
    "| **Lab** | When perceptual uniformity matters; good for color matching |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **BGR is not always best** â€” Different color spaces are better for different tasks\n",
    "2. **Hue separates \"what color\"** from \"how bright\" â€” very useful for segmentation\n",
    "3. **Lab is perceptually uniform** â€” equal distances = equal perceived differences\n",
    "4. **Weighted grayscale** matches human perception better than simple averaging\n",
    "\n",
    "### âœï¸ Final Reflection\n",
    "\n",
    "Answer these questions:\n",
    "\n",
    "1. Which color space worked best for segmenting the sky? Why?\n",
    "2. When might you prefer HSV over Lab (or vice versa)?\n",
    "3. How does this lab connect to Lab 3 (where brightness changes broke your model)?\n",
    "4. Can you think of a computer vision task where color space choice would be critical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your reflection answers:\n",
    "\n",
    "# 1. Best color space for sky segmentation:\n",
    "#    ...\n",
    "\n",
    "# 2. When to prefer HSV vs Lab:\n",
    "#    ...\n",
    "\n",
    "# 3. Connection to Lab 3:\n",
    "#    ...\n",
    "\n",
    "# 4. A task where color space matters:\n",
    "#    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“‹ Submission Checklist\n",
    "\n",
    "Before submitting, make sure:\n",
    "\n",
    "- [ ] Activity 1: `normalize_hsv()` implemented correctly\n",
    "- [ ] HSV sky segmentation attempted with thresholds\n",
    "- [ ] Activity 2: `normalize_hls()` implemented correctly\n",
    "- [ ] HLS sky segmentation attempted\n",
    "- [ ] Activity 3: `normalize_lab()` implemented correctly\n",
    "- [ ] Lab sky segmentation attempted\n",
    "- [ ] Challenge 1: Grayscale bug fixed with explanation\n",
    "- [ ] Challenge 2: Weighted grayscale formula implemented with explanation\n",
    "- [ ] Final reflection questions answered\n",
    "- [ ] All cells executed in order\n",
    "\n",
    "**Grading (10 points total):**\n",
    "\n",
    "| Component | Points |\n",
    "|-----------|--------|\n",
    "| Activity 1: HSV normalization + segmentation | 2 |\n",
    "| Activity 2: HLS normalization + segmentation | 2 |\n",
    "| Activity 3: Lab normalization + segmentation | 2 |\n",
    "| Challenge 1: Fix grayscale bug | 2 |\n",
    "| Challenge 2: Weighted grayscale | 1 |\n",
    "| Final reflection | 1 |\n",
    "\n",
    "**Bonus (+1 point):** Achieve excellent sky segmentation in any color space (minimal false positives/negatives)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
